
å‰ªæç®—æ³•ä¾æ®ï¼š

Learning Efficient Convolutional Networks Through Network Slimmingï¼ˆhttps://arxiv.org/abs/1708.06519ï¼‰

è¯¥æ–¹æ³•åŸºäºBNå±‚ç³»æ•°gammaå‰ªæã€‚

åœ¨ä¸€ä¸ªå·ç§¯-BN-æ¿€æ´»æ¨¡å—ä¸­ï¼ŒBNå±‚å¯ä»¥å®ç°é€šé“çš„ç¼©æ”¾ã€‚å¦‚ä¸‹ï¼š

<p align="center">
<img src="img/Screenshot from 2021-05-25 00-26-23.png">
</p>

BNå±‚çš„å…·ä½“æ“ä½œæœ‰ä¸¤éƒ¨åˆ†ï¼š

<p align="center">
<img src="img/Screenshot from 2021-05-25 00-28-15.png">
</p>

åœ¨å½’ä¸€åŒ–åä¼šè¿›è¡Œçº¿æ€§å˜æ¢ï¼Œé‚£ä¹ˆå½“ç³»æ•°gammaå¾ˆå°æ—¶å€™ï¼Œå¯¹åº”çš„æ¿€æ´»ï¼ˆZoutï¼‰ä¼šç›¸åº”å¾ˆå°ã€‚è¿™äº›å“åº”å¾ˆå°çš„è¾“å‡ºå¯ä»¥è£å‰ªæ‰ï¼Œè¿™æ ·å°±å®ç°äº†bnå±‚çš„é€šé“å‰ªæã€‚

é€šè¿‡åœ¨losså‡½æ•°ä¸­æ·»åŠ gammaçš„L1æ­£åˆ™çº¦æŸï¼Œå¯ä»¥å®ç°gammaçš„ç¨€ç–åŒ–ã€‚

<p align="center">
<img src="img/Screenshot from 2021-05-25 00-28-52.png">
</p>



ä¸Šé¢æŸå¤±å‡½æ•°Lå³è¾¹ç¬¬ä¸€é¡¹æ˜¯åŸå§‹çš„æŸå¤±å‡½æ•°ï¼Œç¬¬äºŒé¡¹æ˜¯çº¦æŸï¼Œå…¶ä¸­g(s) = |s|ï¼ŒÎ»æ˜¯æ­£åˆ™ç³»æ•°ï¼Œæ ¹æ®æ•°æ®é›†è°ƒæ•´

å®é™…è®­ç»ƒçš„æ—¶å€™ï¼Œå°±æ˜¯åœ¨ä¼˜åŒ–Læœ€å°ï¼Œä¾æ®æ¢¯åº¦ä¸‹é™ç®—æ³•ï¼š

â€‹														ğ¿â€²=âˆ‘ğ‘™â€²+ğœ†âˆ‘ğ‘”â€²(ğ›¾)=âˆ‘ğ‘™â€²+ğœ†âˆ‘|ğ›¾|â€²=âˆ‘ğ‘™â€²+ğœ†âˆ‘ğ›¾âˆ—ğ‘ ğ‘–ğ‘”ğ‘›(ğ›¾)

æ‰€ä»¥åªéœ€è¦åœ¨BPä¼ æ’­æ—¶å€™ï¼Œåœ¨BNå±‚æƒé‡ä¹˜ä»¥æƒé‡çš„ç¬¦å·å‡½æ•°è¾“å‡ºå’Œç³»æ•°å³å¯ï¼Œå¯¹åº”æ·»åŠ å¦‚ä¸‹ä»£ç :

```python
            # Backward
            loss.backward()
            # scaler.scale(loss).backward()
            # # ============================= sparsity training ========================== #
            srtmp = opt.sr*(1 - 0.9*epoch/epochs)
            if opt.st:
                ignore_bn_list = []
                for k, m in model.named_modules():
                    if isinstance(m, Bottleneck):
                        if m.add:
                            ignore_bn_list.append(k.rsplit(".", 2)[0] + ".cv1.bn")
                            ignore_bn_list.append(k + '.cv1.bn')
                            ignore_bn_list.append(k + '.cv2.bn')
                    if isinstance(m, nn.BatchNorm2d) and (k not in ignore_bn_list):
                        m.weight.grad.data.add_(srtmp * torch.sign(m.weight.data))  # L1
                        m.bias.grad.data.add_(opt.sr*10 * torch.sign(m.bias.data))  # L1
            # # ============================= sparsity training ========================== #

            optimizer.step()
                # scaler.step(optimizer)  # optimizer.step
                # scaler.update()
            optimizer.zero_grad()
```

è¿™é‡Œå¹¶æœªå¯¹æ‰€æœ‰BNå±‚gammaè¿›è¡Œçº¦æŸï¼Œè¯¦æƒ…è§yolov5sæ¯ä¸ªæ¨¡å— https://blog.csdn.net/IEEE_FELLOW/article/details/117536808
åˆ†æï¼Œè¿™é‡Œå¯¹C3ç»“æ„ä¸­çš„Bottleneckç»“æ„ä¸­æœ‰shortcutçš„å±‚ä¸è¿›è¡Œå‰ªæï¼Œä¸»è¦æ˜¯ä¸ºäº†ä¿æŒtensorç»´åº¦å¯ä»¥åŠ ï¼š

<p align="center">
<img src="img/Screenshot from 2021-05-27 22-20-33.png">
</p>

å®é™…ä¸Šï¼Œåœ¨yolov5ä¸­ï¼Œåªæœ‰backboneä¸­çš„Bottleneckæ˜¯æœ‰shortcutçš„ï¼ŒHeadä¸­å…¨éƒ¨æ²¡æœ‰shortcut.

å¦‚æœä¸åŠ L1æ­£åˆ™çº¦æŸï¼Œè®­ç»ƒç»“æŸåçš„BNå±‚gammaåˆ†å¸ƒè¿‘ä¼¼æ­£å¤ªåˆ†å¸ƒï¼š

<p align="center">
<img src="img/Screenshot from 2021-05-23 20-19-08.png">
</p>

æ˜¯æ— æ³•è¿›è¡Œå‰ªæçš„ã€‚

ç¨€ç–è®­ç»ƒåçš„åˆ†å¸ƒï¼š

<p align="center">
<img src="img/Screenshot from 2021-05-23 20-19-30.png">
</p>

å¯ä»¥çœ‹åˆ°ï¼Œéšç€è®­ç»ƒepochè¿›è¡Œï¼Œè¶Šæ¥è¶Šå¤šçš„gammaé€¼è¿‘0.

è®­ç»ƒå®Œæˆåå¯ä»¥è¿›è¡Œå‰ªæï¼Œä¸€ä¸ªåŸºæœ¬çš„åŸåˆ™æ˜¯é˜ˆå€¼ä¸èƒ½å¤§äºä»»ä½•é€šé“bnçš„æœ€å¤§gammaã€‚ç„¶åæ ¹æ®è®¾å®šçš„è£å‰ªæ¯”ä¾‹å‰ªæã€‚

å‰ªæ‰ä¸€ä¸ªBNå±‚ï¼Œéœ€è¦å°†å¯¹åº”ä¸Šä¸€å±‚çš„å·ç§¯æ ¸è£å‰ªæ‰ï¼ŒåŒæ—¶å°†ä¸‹ä¸€å±‚å·ç§¯æ ¸å¯¹åº”çš„é€šé“å‡æ‰ã€‚

è¿™é‡Œåœ¨æŸä¸ªæ•°æ®é›†ä¸Šå®éªŒã€‚

é¦–å…ˆä½¿ç”¨train.pyè¿›è¡Œæ­£å¸¸è®­ç»ƒï¼š

```
python train.py --weights yolov5s.pt --adam --epochs 100
```

ç„¶åç¨€ç–è®­ç»ƒï¼š

```
python train_sparsity.py --st --sr 0.0001 --weights yolov5s.pt --adam --epochs 100
```

srçš„é€‰æ‹©éœ€è¦æ ¹æ®æ•°æ®é›†è°ƒæ•´ï¼Œå¯ä»¥é€šè¿‡è§‚å¯Ÿtensorboardçš„mapï¼Œgammaå˜åŒ–ç›´æ–¹å›¾ç­‰é€‰æ‹©ã€‚
åœ¨run/train/exp*/ç›®å½•ä¸‹:
```
tensorboard --logdir .
```
ç„¶åç‚¹å‡»å‡ºç°çš„é“¾æ¥è§‚å¯Ÿè®­ç»ƒä¸­çš„å„é¡¹æŒ‡æ ‡.

è®­ç»ƒå®Œæˆåè¿›è¡Œå‰ªæï¼š

```
python prune.py --weights runs/train/exp1/weights/last.pt --percent 0.5 --cfg models/yolov5s.yaml
```

è£å‰ªæ¯”ä¾‹percentæ ¹æ®æ•ˆæœè°ƒæ•´ï¼Œå¯ä»¥ä»å°åˆ°å¤§è¯•ã€‚æ³¨æ„cfgçš„æ¨¡å‹æ–‡ä»¶éœ€è¦å’Œweightså¯¹åº”ä¸Š,å¦åˆ™ä¼šå‡ºç°[è¿è¡Œprune è¿‡ç¨‹ä¸­å‡ºç°é”®å€¼ä¸å¯¹åº”çš„é—®é¢˜](https://github.com/midasklr/yolov5prune/issues/65),è£å‰ªå®Œæˆä¼šä¿å­˜å¯¹åº”çš„æ¨¡å‹pruned_model.ptã€‚

å¾®è°ƒï¼š

```
python finetune_pruned.py --weights pruned_model.pt --adam --epochs 100
```

åœ¨VOC2007æ•°æ®é›†ä¸Šå®éªŒ,è®­ç»ƒé›†ä¸ºVOC07 trainval, æµ‹è¯•é›†ä¸ºVOC07 test.ä½œä¸ºå¯¹æ¯”,è¿™é‡Œåˆ—ä¸¾äº†faster rcnnå’ŒSSD512åœ¨ç›¸åŒæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœ, yolov5è¾“å…¥å¤§å°ä¸º512.ä¸ºäº†èŠ‚çœæ—¶é—´,è¿™é‡Œä½¿ç”¨AdamWè®­ç»ƒ100 epoch.

| model             | optim&epoch | sparity | mAP@.5      | mode size | forward time |
| ----------------- | ----------- | ------- | ----------- | --------- | ------------ |
| faster rcnn       |             | -       | 69.9(paper) |           |              |
| SSD512            |             | -       | 71.6(paper) |           |              |
| yolov5s           | sgd 300     | 0       | 67.4        |           |              |
| yolov5s           | adamw 100   | 0       | 66.3        |           |              |
| yolov5s           | adamw 100   | 0.0001  | 69.2        |           |              |
| yolov5s           | sgd 300     | 0.001   | Inf. error  |           |              |
| yolov5s           | adamw 100   | 0.001   | 65.7        | 28.7      | 7.32 ms      |
| 55% prune yolov5s |             |         | 64.1        | 8.6       | 7.30 ms      |
| fine-tune above   |             |         | 67.3        |           | 7.21 ms      |
| yolov5l           | adamw 100   | 0       | 70.1        |           |              |
| yolov5l           | adamw 100   | 0.001   | 0.659       |           | 12.95 ms     |



åœ¨è‡ªå·±æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœ:

| model                 | sparity | map   | mode size |
| --------------------- | ------- | ----- | --------- |
| yolov5s               | 0       | 0.322 | 28.7 M    |
| sparity train yolov5s | 0.001   | 0.325 | 28.7 M    |
| 65% pruned yolov5s    | 0.001   | 0.318 | 6.8 M     |
| fine-tune             | 0       | 0.325 | 6.8 M     |


